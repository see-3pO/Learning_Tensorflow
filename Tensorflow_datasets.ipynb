{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIwudy9QWD0f3ln3dUBGCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8edc18a5857642e381b558180433cc94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a1fe97a51174a88a95069bcdea81d76",
              "IPY_MODEL_8ed8ef1b87de4c8cb56ca21358cedccd",
              "IPY_MODEL_871a77d4a1ee4ba191ba3d3643f41d50"
            ],
            "layout": "IPY_MODEL_c83dbf48e9244650aaa1f24e34d89c1a"
          }
        },
        "5a1fe97a51174a88a95069bcdea81d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e66b18424643f5a70ea798431cb203",
            "placeholder": "​",
            "style": "IPY_MODEL_fbe8cf53601e42b597bc7b4518051c7e",
            "value": "Dl Completed...: 100%"
          }
        },
        "8ed8ef1b87de4c8cb56ca21358cedccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367e2ec100894088afdfc3261a4e2c22",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93f45317007d4221a74af0c3b6e460b1",
            "value": 5
          }
        },
        "871a77d4a1ee4ba191ba3d3643f41d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_166b9cb6461a4024b1100374bea032e0",
            "placeholder": "​",
            "style": "IPY_MODEL_5f536bdccc114741b0b76b364884b975",
            "value": " 5/5 [00:00&lt;00:00, 11.07 file/s]"
          }
        },
        "c83dbf48e9244650aaa1f24e34d89c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e66b18424643f5a70ea798431cb203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe8cf53601e42b597bc7b4518051c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "367e2ec100894088afdfc3261a4e2c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f45317007d4221a74af0c3b6e460b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "166b9cb6461a4024b1100374bea032e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f536bdccc114741b0b76b364884b975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/see-3pO/Learning_Tensorflow/blob/master/Tensorflow_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow Datasets is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks, such as Jax."
      ],
      "metadata": {
        "id": "dpxszhhKV_cT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dPv-ueEULRa"
      },
      "outputs": [],
      "source": [
        "#  basic imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Loading with TFDS"
      ],
      "metadata": {
        "id": "aQ-87my_qibb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the mnist dataset\n",
        "(ds_train, ds_test), ds_info = tfds.load(\"mnist\",\n",
        "                                         split=[\"train\", \"test\"],\n",
        "                                         as_supervised=True, # return (image, label) otherwise returns dict\n",
        "                                         shuffle_files=True,\n",
        "                                         with_info=True,\n",
        "                                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "8edc18a5857642e381b558180433cc94",
            "5a1fe97a51174a88a95069bcdea81d76",
            "8ed8ef1b87de4c8cb56ca21358cedccd",
            "871a77d4a1ee4ba191ba3d3643f41d50",
            "c83dbf48e9244650aaa1f24e34d89c1a",
            "17e66b18424643f5a70ea798431cb203",
            "fbe8cf53601e42b597bc7b4518051c7e",
            "367e2ec100894088afdfc3261a4e2c22",
            "93f45317007d4221a74af0c3b6e460b1",
            "166b9cb6461a4024b1100374bea032e0",
            "5f536bdccc114741b0b76b364884b975"
          ]
        },
        "id": "cApIIrfDWWoD",
        "outputId": "bea29824-94c5-411d-8d9b-7312e0114848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8edc18a5857642e381b558180433cc94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shuffle_files: used to specify  whether the files that make up a dataset should be shuffled before being loaded and processed. Normally, large datasets are split across multiple files.\n"
      ],
      "metadata": {
        "id": "cydEHKdTXlPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I49SfQBTa3KH",
        "outputId": "c88c2429-420e-4ec7-87ab-6069f79d564f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    full_name='mnist/3.0.1',\n",
            "    description=\"\"\"\n",
            "    The MNIST database of handwritten digits.\n",
            "    \"\"\",\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    data_dir='/root/tensorflow_datasets/mnist/3.0.1.incompleteFS70XA',\n",
            "    file_format=tfrecord,\n",
            "    download_size=11.06 MiB,\n",
            "    dataset_size=21.00 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image(image, label):\n",
        "  # normalize the image\n",
        "  return tf.cast(image, tf.float32)/255.0, label"
      ],
      "metadata": {
        "id": "V6A5gYU2bbxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "gOlcjcfvmopO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train set\n",
        "ds_train = ds_train.map(normalize_image, num_parallel_calls=AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "# test set\n",
        "ds_test = ds_test.map(normalize_image, num_parallel_calls=AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "v5vU2TajknDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a model\n",
        "model = keras.Sequential([\n",
        "    keras.Input((28, 28, 1)),\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10),\n",
        "])"
      ],
      "metadata": {
        "id": "MqdVIe3VoHkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "8UWDD4yjoqXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(ds_train, epochs=5, verbose=2)\n",
        "model.evaluate(ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk2_JuSPo-nP",
        "outputId": "09cd0109-d7d7-4d3d-d3e7-9b31118c93dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 - 23s - loss: 0.2051 - accuracy: 0.9420 - 23s/epoch - 24ms/step\n",
            "Epoch 2/5\n",
            "938/938 - 15s - loss: 0.0733 - accuracy: 0.9786 - 15s/epoch - 16ms/step\n",
            "Epoch 3/5\n",
            "938/938 - 15s - loss: 0.0542 - accuracy: 0.9839 - 15s/epoch - 16ms/step\n",
            "Epoch 4/5\n",
            "938/938 - 15s - loss: 0.0416 - accuracy: 0.9872 - 15s/epoch - 16ms/step\n",
            "Epoch 5/5\n",
            "938/938 - 15s - loss: 0.0332 - accuracy: 0.9902 - 15s/epoch - 16ms/step\n",
            "79/79 [==============================] - 3s 25ms/step - loss: 0.0619 - accuracy: 0.9811\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0618802048265934, 0.9811000227928162]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Loading with TDFS"
      ],
      "metadata": {
        "id": "KI5bQzz7qTki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'imdb_reviews',\n",
        "    split = ['train', 'test'],\n",
        "    shuffle_files = True,\n",
        "    as_supervised = True,\n",
        "    with_info = True\n",
        ")\n",
        "\n",
        "print(ds_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0FhrtLYp5SK",
        "outputId": "59cdbd3e-771b-4d91-e386-503e1e9fdbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='imdb_reviews',\n",
            "    full_name='imdb_reviews/plain_text/1.0.0',\n",
            "    description=\"\"\"\n",
            "    Large Movie Review Dataset. This is a dataset for binary sentiment\n",
            "    classification containing substantially more data than previous benchmark\n",
            "    datasets. We provide a set of 25,000 highly polar movie reviews for training,\n",
            "    and 25,000 for testing. There is additional unlabeled data for use as well.\n",
            "    \"\"\",\n",
            "    config_description=\"\"\"\n",
            "    Plain text\n",
            "    \"\"\",\n",
            "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
            "    data_dir='/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=80.23 MiB,\n",
            "    dataset_size=129.83 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
            "        'text': Text(shape=(), dtype=string),\n",
            "    }),\n",
            "    supervised_keys=('text', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=25000, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=25000, num_shards=1>,\n",
            "        'unsupervised': <SplitInfo num_examples=50000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "      month     = {June},\n",
            "      year      = {2011},\n",
            "      address   = {Portland, Oregon, USA},\n",
            "      publisher = {Association for Computational Linguistics},\n",
            "      pages     = {142--150},\n",
            "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "# tokenizer = tfds.features.text.Tokenizer()\n",
        "# above is deprecated but can still be accessed using\n",
        "tokenizer = tfds.deprecated.text.Tokenizer()"
      ],
      "metadata": {
        "id": "Mhftit8ArbDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import collections\n",
        "\n",
        "word_counter = collections.Counter()\n",
        "\n",
        "```\n",
        "- Purpose: To count the occurrences of each word across the entire dataset. collections.Counter is a specialized dictionary for counting hashable objects.\n",
        "\n",
        "- Reason: It provides a convenient way to count word frequencies and can be easily updated with new data.\n",
        "\n",
        "```python\n",
        "for text, _ in dataset:\n",
        "    words = tokenizer.tokenize(text.numpy().decode('utf-8').lower())\n",
        "    word_counter.update(words)\n",
        "\n",
        "```\n",
        "`.decode('utf-8')`: Decodes the byte string to a regular string. This is necessary because TensorFlow datasets often store strings as byte strings."
      ],
      "metadata": {
        "id": "fyli6KJ4xA66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "def build_vocabulary(dataset, tokenizer, min_count):\n",
        "  # initialize a counter to count word occurrences\n",
        "  word_counter = collections.Counter()\n",
        "\n",
        "  # iterate over the dataset and update word counts\n",
        "  for text, _ in ds_train:\n",
        "    words = tokenizer.tokenize(text.numpy().decode('utf-8').lower())\n",
        "    word_counter.update(words)\n",
        "\n",
        "  # build the vocabulary set with words that meet the min count\n",
        "  vocabulary = { word for word, count in word_counter.items() if count>= min_count}\n",
        "\n",
        "  return vocabulary"
      ],
      "metadata": {
        "id": "x82zbV7vsvN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = build_vocabulary(ds_train, tokenizer, 5)\n",
        "print(len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ6AuzW82vFu",
        "outputId": "f9f4dabf-13fc-4a12-dfff-9412a9587a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the tokenized words into numerical format(interger IDs) using an encoder\n",
        "# oov_token: out of vocabulary token\n",
        "# <UNK> stands for unknown. If word in your text is not in the vocabulary, it will be replaced by this token\n",
        "\n",
        "encoder = tfds.deprecated.text.TokenTextEncoder(\n",
        "    vocabulary, oov_token='<UNK>', lowercase=True, tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "njWsrwEv3CEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding function\n",
        "def my_encoding(text_tensor, label):\n",
        "  # convert tensor to string\n",
        "  text = text_tensor.numpy().decode('utf-8') # convert tenspr to string\n",
        "  # encode the text using encoder\n",
        "  encoded_text = encoder.encode(text)\n",
        "  return encoded_text, label"
      ],
      "metadata": {
        "id": "UcpM1ZSB5KbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # wrap the function with a `tf.py_function`\n",
        " # This allows TensorFlow to call the Python function within its data pipeline.\n",
        "def tf_my_encoding(text, label):\n",
        "  encoded_text, label = tf.py_function(\n",
        "      my_encoding, # python function to execute\n",
        "      inp=[text, label], # expected inputs to the function\n",
        "      Tout=(tf.int64, label.dtype) # expected output types\n",
        "  )\n",
        "  print(\"Encoded Text Shape:\", encoded_text.shape)\n",
        "  print(\"Label Shape:\", label.shape)\n",
        "  encoded_text.set_shape([None])\n",
        "  label.set_shape(label, [])\n",
        "\n",
        "  return encoded_text, label"
      ],
      "metadata": {
        "id": "rh4ZgjKvBQnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `num_parallel_calls=AUTOTUNE` allows TensorFlow to automatically choose the number of CPU cores to use for parallel processing, optimizing performance.\n",
        "\n",
        "```python\n",
        "encoded_ds_train = encoded_ds_train.padded_batch(32, padded_shapes=([None], ()))\n",
        "```\n",
        "- This creates batches of size 32, where each batch is padded to the maximum length of the sequences in that batch.\n",
        "- `padded_shapes=([None], ())` specifies that the input sequences can have variable lengths (indicated by None), and the labels are scalar values (indicated by ()).\n",
        "- Padding sequences ensures that all sequences within a batch have the same length, which is necessary for efficient batch processing in deep learning models."
      ],
      "metadata": {
        "id": "33_uPbZlFCs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply to the dataset\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "encoded_ds_train = ds_train.map(tf_my_encoding, num_parallel_calls=AUTOTUNE).cache()\n",
        "encoded_ds_train = encoded_ds_train.shuffle(10000)\n",
        "encoded_ds_train = encoded_ds_train.padded_batch(32, padded_shapes=([None], ()))\n",
        "encoded_ds_train = encoded_ds_train.prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "NbWcVXcxDfcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_ds_test = ds_test.map(tf_my_encoding)\n",
        "encoded_ds_test = ds_test.padded_batch(32, padded_shapes=([None], []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "twsajVx9Ftdq",
        "outputId": "94cb20e5-3cfc-4023-c564-739d7d98e0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Text Shape: <unknown>\n",
            "Label Shape: <unknown>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The padded shape (None,) is not compatible with the shape () of the corresponding input component.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6b46ceb7fbc8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoded_ds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_my_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_ds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mpadded_batch\u001b[0;34m(self, batch_size, padded_shapes, padding_values, drop_remainder, name)\u001b[0m\n\u001b[1;32m   2005\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpadded_batch_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m     return padded_batch_op._padded_batch(self, batch_size, padded_shapes,\n\u001b[0m\u001b[1;32m   2008\u001b[0m                                          padding_values, drop_remainder, name)\n\u001b[1;32m   2009\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/padded_batch_op.py\u001b[0m in \u001b[0;36m_padded_batch\u001b[0;34m(input_dataset, batch_size, padded_shapes, padding_values, drop_remainder, name)\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise ValueError(f\"You must provide `padded_shapes` argument because \"\n\u001b[1;32m     45\u001b[0m                          f\"component {i} has unknown rank.\")\n\u001b[0;32m---> 46\u001b[0;31m   return _PaddedBatchDataset(\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/padded_batch_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, batch_size, padded_shapes, padding_values, drop_remainder, name)\u001b[0m\n\u001b[1;32m    214\u001b[0m         nest.flatten(input_shapes), flat_padded_shapes):\n\u001b[1;32m    215\u001b[0m       flat_padded_shapes_as_tensors.append(\n\u001b[0;32m--> 216\u001b[0;31m           _padded_shape_to_tensor(padded_shape, input_component_shape))\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     self._padded_shapes = nest.pack_sequence_as(input_shapes,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/padded_batch_op.py\u001b[0m in \u001b[0;36m_padded_shape_to_tensor\u001b[0;34m(padded_shape, input_component_shape)\u001b[0m\n\u001b[1;32m    121\u001b[0m   if not _is_padded_shape_compatible_with(padded_shape_as_shape,\n\u001b[1;32m    122\u001b[0m                                           input_component_shape):\n\u001b[0;32m--> 123\u001b[0;31m     raise ValueError(f\"The padded shape {padded_shape_as_shape} is not \"\n\u001b[0m\u001b[1;32m    124\u001b[0m                      \u001b[0;34mf\"compatible with the shape {input_component_shape} of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                      f\"the corresponding input component.\")\n",
            "\u001b[0;31mValueError\u001b[0m: The padded shape (None,) is not compatible with the shape () of the corresponding input component."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Architecture**\n",
        "\n",
        "The model consists of the following layers:\n",
        "\n",
        "1. **Masking Layer:**\n",
        "\n",
        "**Purpose:** Ignores padded values during computation. This layer is useful when dealing with sequences of variable lengths and ensures that the model doesn't process padded values, which could negatively affect the model's predictions.\n",
        "\n",
        "**Arguments:**\n",
        "\n",
        "`mask_value=0`: Specifies the value to be treated as a mask. In this case, it's set to 0, assuming that 0 represents padding in the input sequences.\n",
        "\n",
        "\n",
        "2. **Embedding Layer:**\n",
        "\n",
        "**Purpose:** Converts integer-encoded words into dense vectors of fixed size (output_dim=32).\n",
        "\n",
        "**Arguments:**\n",
        "\n",
        "`input_dim=len(vocabulary) + 2`: Specifies the size of the vocabulary plus two additional tokens. The additional tokens might be reserved for out-of-vocabulary words and masked values.\n",
        "\n",
        "`output_dim=32`: Specifies the dimensionality of the dense embedding vectors.\n",
        "\n",
        "\n",
        "3. **GlobalAveragePooling1D Layer:**\n",
        "\n",
        "**Purpose:** Averages the embedding vectors across the time dimension, effectively reducing the sequence length to a single vector.\n",
        "\n",
        "**Explanation:** This layer helps in reducing the model's complexity and mitigates the risk of overfitting by summarizing the information across the entire sequence.\n",
        "\n",
        "\n",
        "4. **Dense Layer (ReLU Activation):**\n",
        "\n",
        "**Purpose:** Applies a dense layer with ReLU activation to introduce non-linearity and increase the model's capacity to learn complex patterns in the data.\n",
        "\n",
        "**Arguments:**\n",
        "\n",
        "`units=64`: Specifies the number of neurons in the layer.\n",
        "\n",
        "`activation='relu'`: Specifies the rectified linear unit (ReLU) activation function.\n",
        "\n",
        "\n",
        "5. **Dense Layer (Linear Activation):**\n",
        "\n",
        "**Purpose:** Outputs a single value, representing the model's prediction.\n",
        "\n",
        "**Explanation:** Since this is a binary classification problem, a single neuron with a linear activation function is used to produce a continuous output. The output can be interpreted as the model's confidence score or probability for the positive class."
      ],
      "metadata": {
        "id": "ivldVBbDJSYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = keras.Sequential([\n",
        "    # ingnore the 0s added during padding\n",
        "    layers.Masking(mask_value=0),\n",
        "    #\n",
        "    layers.Embedding(input_dim=len(vocabulary)+2, output_dim=32),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1) # less the 0: negative, greater or equal than 0: positive\n",
        "])"
      ],
      "metadata": {
        "id": "v5WoVPyuGNWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "  optimizer = keras.optimizers.Adam(3e-4, clipnorm=1),\n",
        "  metrics = ['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "49o2bbWUH4CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(encoded_ds_train, epochs=10, verbose=2)\n",
        "model.evaluate(encoded_ds_test)"
      ],
      "metadata": {
        "id": "gUnv3GLeI3Yz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}